{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inteligência Artificial na Era do E-commerce: Previsão de Vendas Semanais (MLDS)\n",
        "\n",
        "Este notebook implementa:\n",
        "- EDA detalhada do dataset `Asset/sales.csv`.\n",
        "- Preparação/limpeza de dados e engenharia de atributos temporais e lags.\n",
        "- Validação temporal (TimeSeriesSplit) e métricas (MAE, RMSE, MAPE, R²).\n",
        "- Treino e comparação de modelos (Linear, Ridge, Lasso, RandomForest, GradientBoosting).\n",
        "- Seleção do melhor modelo e avaliação em holdout final.\n",
        "- Persistência do melhor pipeline em `models/best_model.joblib`.\n",
        "- **Previsão futura**: projeção de vendas para as próximas semanas usando o modelo treinado.\n",
        "\n",
        "Observação: o dashboard Streamlit está disponível em `streamlit_app.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m warnings.filterwarnings(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "# Imports e configurações\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "\n",
        "from joblib import dump\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "DATA_PATH = os.path.join('Asset', 'sales.csv')\n",
        "MODELS_DIR = os.path.join('models')\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregamento e limpeza básica\n",
        "df_raw = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# Padroniza nomes de colunas\n",
        "df_raw.columns = [c.strip() for c in df_raw.columns]\n",
        "\n",
        "# Conversões de tipos e ajustes conforme dicionário de dados\n",
        "df = df_raw.copy()\n",
        "# Especifica o formato da data: DD-MM-YYYY\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
        "\n",
        "# Ajustes de escala\n",
        "if 'Fuel_Price' in df.columns:\n",
        "    df['Fuel_Price'] = df['Fuel_Price'] / 1000.0\n",
        "if 'Unemployment' in df.columns:\n",
        "    df['Unemployment'] = df['Unemployment'] / 1000.0\n",
        "\n",
        "# Ordena por data\n",
        "df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# EDA rápida\n",
        "display(df.head())\n",
        "display(df.describe(include='all'))\n",
        "print('Perdas por coluna:')\n",
        "print(df.isna().sum())\n",
        "\n",
        "# Checagem de periodicidade semanal (opcional)\n",
        "df['week_diff'] = df['Date'].diff().dt.days\n",
        "print('Resumo dif (dias) entre registros:\\n', df['week_diff'].describe())\n",
        "df = df.drop(columns=['week_diff'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funções utilitárias: métricas\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    mask = y_true != 0\n",
        "    if mask.sum() == 0:\n",
        "        return np.nan\n",
        "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))\n",
        "\n",
        "\n",
        "def evaluate_regression(y_true, y_pred):\n",
        "    return {\n",
        "        'MAE': mean_absolute_error(y_true, y_pred),\n",
        "        'RMSE': rmse(y_true, y_pred),\n",
        "        'MAPE': mape(y_true, y_pred),\n",
        "        'R2': r2_score(y_true, y_pred)\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Engenharia de atributos para série temporal\n",
        "\n",
        "def add_time_features(frame: pd.DataFrame) -> pd.DataFrame:\n",
        "    d = frame.copy()\n",
        "    d['year'] = d['Date'].dt.year\n",
        "    d['month'] = d['Date'].dt.month\n",
        "    d['weekofyear'] = d['Date'].dt.isocalendar().week.astype(int)\n",
        "    d['quarter'] = d['Date'].dt.quarter\n",
        "    # Sazonalidade cíclica (semana do ano)\n",
        "    d['sin_woy'] = np.sin(2 * np.pi * d['weekofyear'] / 52.0)\n",
        "    d['cos_woy'] = np.cos(2 * np.pi * d['weekofyear'] / 52.0)\n",
        "    return d\n",
        "\n",
        "\n",
        "def add_lag_rolling_features(frame: pd.DataFrame, target_col: str = 'Weekly_Sales') -> pd.DataFrame:\n",
        "    d = frame.copy()\n",
        "    lags = [1, 2, 3, 4, 52]\n",
        "    for lag in lags:\n",
        "        d[f'{target_col}_lag_{lag}'] = d[target_col].shift(lag)\n",
        "    # Janelas móveis (semana)\n",
        "    d[f'{target_col}_roll_mean_4'] = d[target_col].shift(1).rolling(window=4, min_periods=2).mean()\n",
        "    d[f'{target_col}_roll_std_4'] = d[target_col].shift(1).rolling(window=4, min_periods=2).std()\n",
        "    d[f'{target_col}_roll_mean_12'] = d[target_col].shift(1).rolling(window=12, min_periods=4).mean()\n",
        "    d[f'{target_col}_roll_std_12'] = d[target_col].shift(1).rolling(window=12, min_periods=4).std()\n",
        "    return d\n",
        "\n",
        "\n",
        "def build_features(frame: pd.DataFrame) -> pd.DataFrame:\n",
        "    d = add_time_features(frame)\n",
        "    d = add_lag_rolling_features(d, target_col='Weekly_Sales')\n",
        "    # Ajuste de tipos categóricos/booleanos\n",
        "    if 'Holiday_Flag' in d.columns:\n",
        "        d['Holiday_Flag'] = d['Holiday_Flag'].astype(int)\n",
        "    return d\n",
        "\n",
        "\n",
        "# Aplica engenharia de atributos\n",
        "df_feat = build_features(df)\n",
        "\n",
        "# Remove linhas com NaN geradas por lags/rollings\n",
        "min_index = df_feat.dropna().index.min()\n",
        "df_model = df_feat.loc[min_index:].reset_index(drop=True)\n",
        "\n",
        "print('Shape após features:', df_model.shape)\n",
        "display(df_model.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparação de variáveis e colunas\n",
        "TARGET = 'Weekly_Sales'\n",
        "DATE_COL = 'Date'\n",
        "\n",
        "feature_cols = [c for c in df_model.columns if c not in [TARGET, DATE_COL]]\n",
        "num_cols = []\n",
        "cat_cols = []\n",
        "for c in feature_cols:\n",
        "    if pd.api.types.is_numeric_dtype(df_model[c]):\n",
        "        num_cols.append(c)\n",
        "    else:\n",
        "        cat_cols.append(c)\n",
        "\n",
        "print('Num cols:', len(num_cols))\n",
        "print('Cat cols:', len(cat_cols))\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, num_cols),\n",
        "        ('cat', categorical_transformer, cat_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "X = df_model[feature_cols]\n",
        "y = df_model[TARGET]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuração de validação temporal (TimeSeriesSplit)\n",
        "N_SPLITS = 5\n",
        "MIN_TRAIN_SIZE = int(len(df_model) * 0.5)\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=N_SPLITS)\n",
        "\n",
        "models = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'Ridge': Ridge(random_state=RANDOM_STATE),\n",
        "    'Lasso': Lasso(random_state=RANDOM_STATE),\n",
        "    'RandomForest': RandomForestRegressor(n_estimators=400, random_state=RANDOM_STATE, n_jobs=-1),\n",
        "    'GradientBoosting': GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
        "}\n",
        "\n",
        "cv_results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    fold_metrics = []\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
        "        if train_idx.shape[0] < MIN_TRAIN_SIZE:\n",
        "            continue\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        pipe = Pipeline(steps=[('pre', preprocessor), ('model', model)])\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_pred = pipe.predict(X_val)\n",
        "        metrics = evaluate_regression(y_val, y_pred)\n",
        "        metrics['fold'] = fold_idx\n",
        "        metrics['model'] = name\n",
        "        fold_metrics.append(metrics)\n",
        "    if fold_metrics:\n",
        "        dfm = pd.DataFrame(fold_metrics)\n",
        "        dfm['model'] = name\n",
        "        cv_results.append(dfm)\n",
        "\n",
        "cv_results = pd.concat(cv_results, ignore_index=True)\n",
        "display(cv_results.groupby('model')[['MAE','RMSE','MAPE','R2']].mean().sort_values('RMSE'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seleção do melhor modelo por RMSE médio e avaliação em holdout final\n",
        "\n",
        "summary = cv_results.groupby('model')[['MAE','RMSE','MAPE','R2']].mean().sort_values('RMSE')\n",
        "best_model_name = summary.index[0]\n",
        "print('Melhor modelo (CV):', best_model_name)\n",
        "\n",
        "test_size = int(len(X) * 0.15)\n",
        "X_train_full, X_test = X.iloc[:-test_size], X.iloc[-test_size:]\n",
        "y_train_full, y_test = y.iloc[:-test_size], y.iloc[-test_size:]\n",
        "\n",
        "best_estimator = models[best_model_name]\n",
        "pipe_best = Pipeline(steps=[('pre', preprocessor), ('model', best_estimator)])\n",
        "pipe_best.fit(X_train_full, y_train_full)\n",
        "\n",
        "y_pred_test = pipe_best.predict(X_test)\n",
        "metrics_test = evaluate_regression(y_test, y_pred_test)\n",
        "print('Métricas holdout final:', metrics_test)\n",
        "\n",
        "# Persistência\n",
        "best_path = os.path.join(MODELS_DIR, 'best_model.joblib')\n",
        "dump({'pipeline': pipe_best, 'model_name': best_model_name, 'features': feature_cols, 'target': TARGET}, best_path)\n",
        "print('Modelo salvo em:', best_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gráficos: importância de atributos e comparação de verdade vs predito\n",
        "\n",
        "# Importância: só para modelos baseados em árvore/linear com atributo\n",
        "importances = None\n",
        "if hasattr(pipe_best.named_steps['model'], 'feature_importances_'):\n",
        "    # Para modelos com feature_importances_ (RandomForest, GradientBoosting)\n",
        "    importances = pipe_best.named_steps['model'].feature_importances_\n",
        "    \n",
        "    # Recupera nomes após preprocessamento - precisa ajustar o preprocessor primeiro\n",
        "    preprocessor_fitted = pipe_best.named_steps['pre']\n",
        "    \n",
        "    # Cria um DataFrame de exemplo para obter os nomes das features\n",
        "    X_sample = X.iloc[:1]  # Uma linha de exemplo\n",
        "    X_transformed = preprocessor_fitted.transform(X_sample)\n",
        "    \n",
        "    # Obtém nomes das features numéricas\n",
        "    num_names = num_cols\n",
        "    \n",
        "    # Obtém nomes das features categóricas após one-hot encoding\n",
        "    cat_feature_names = []\n",
        "    if cat_cols:\n",
        "        try:\n",
        "            ohe = preprocessor_fitted.named_transformers_['cat'].named_steps['onehot']\n",
        "            cat_feature_names = list(ohe.get_feature_names_out(cat_cols))\n",
        "        except:\n",
        "            # Fallback: usa nomes originais se não conseguir obter os nomes transformados\n",
        "            cat_feature_names = cat_cols\n",
        "    \n",
        "    feature_names = num_names + cat_feature_names\n",
        "    \n",
        "    # Cria DataFrame com importâncias\n",
        "    imp_df = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False).head(20)\n",
        "    \n",
        "    plt.figure(figsize=(10,6))\n",
        "    sns.barplot(data=imp_df, x='importance', y='feature', color='#4C72B0')\n",
        "    plt.title('Top 20 Importâncias de Atributos')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "elif hasattr(pipe_best.named_steps['model'], 'coef_') and hasattr(pipe_best.named_steps['model'], 'intercept_'):\n",
        "    # Para modelos lineares, coeficientes após padronização (interpretação relativa)\n",
        "    coefs = pipe_best.named_steps['model'].coef_\n",
        "    \n",
        "    # Recupera nomes após preprocessamento\n",
        "    preprocessor_fitted = pipe_best.named_steps['pre']\n",
        "    \n",
        "    # Obtém nomes das features numéricas\n",
        "    num_names = num_cols\n",
        "    \n",
        "    # Obtém nomes das features categóricas após one-hot encoding\n",
        "    cat_feature_names = []\n",
        "    if cat_cols:\n",
        "        try:\n",
        "            ohe = preprocessor_fitted.named_transformers_['cat'].named_steps['onehot']\n",
        "            cat_feature_names = list(ohe.get_feature_names_out(cat_cols))\n",
        "        except:\n",
        "            # Fallback: usa nomes originais se não conseguir obter os nomes transformados\n",
        "            cat_feature_names = cat_cols\n",
        "    \n",
        "    feature_names = num_names + cat_feature_names\n",
        "    \n",
        "    coef_df = pd.DataFrame({'feature': feature_names, 'coef': coefs}).sort_values('coef', ascending=False)\n",
        "    \n",
        "    plt.figure(figsize=(10,6))\n",
        "    sns.barplot(data=coef_df.head(20), x='coef', y='feature', color='#55A868')\n",
        "    plt.title('Top 20 Coeficientes (escala padronizada)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Verdade vs predito no holdout final\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(df_model[DATE_COL].iloc[-len(y_test):], y_test.values, label='Verdade', linewidth=2)\n",
        "plt.plot(df_model[DATE_COL].iloc[-len(y_test):], y_pred_test, label='Predito', linewidth=2)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.title('Comparação Verdade vs Predito (Holdout)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Previsão Futura: Projeção de vendas para as próximas semanas\n",
        "\n",
        "def forecast_future(df_historical: pd.DataFrame, pipe, feature_cols: list, n_weeks: int = 12) -> pd.DataFrame:\n",
        "    \"\"\"Gera previsões futuras usando o modelo treinado.\"\"\"\n",
        "    predictions = []\n",
        "    df_working = df_historical.copy()\n",
        "    \n",
        "    # Gera datas futuras\n",
        "    last_date = df_historical['Date'].max()\n",
        "    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=7), periods=n_weeks, freq='W')\n",
        "    \n",
        "    # Prepara última linha como base\n",
        "    last_row = df_historical.iloc[-1]\n",
        "    recent_mean = df_historical.iloc[-12:].mean()\n",
        "    \n",
        "    for i in range(n_weeks):\n",
        "        # Cria DataFrame temporário com histórico + previsões anteriores + nova semana\n",
        "        future_row_dict = {'Date': future_dates[i]}\n",
        "        \n",
        "        # Features externas (usa médias recentes)\n",
        "        for col in ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Holiday_Flag']:\n",
        "            if col in df_historical.columns:\n",
        "                future_row_dict[col] = recent_mean.get(col, last_row.get(col, 0))\n",
        "        \n",
        "        # Adiciona previsão temporária (0) para calcular lags/rolling\n",
        "        future_row_dict['Weekly_Sales'] = 0\n",
        "        \n",
        "        # Converte para DataFrame\n",
        "        future_row_df = pd.DataFrame([future_row_dict])\n",
        "        future_row_df = add_time_features(future_row_df)\n",
        "        \n",
        "        # Concatena com histórico + previsões anteriores para calcular lags/rolling\n",
        "        df_temp = pd.concat([df_working, future_row_df], ignore_index=True)\n",
        "        df_temp = add_lag_rolling_features(df_temp, target_col='Weekly_Sales')\n",
        "        \n",
        "        # Extrai apenas a última linha (semana futura) com todas as features\n",
        "        future_row = df_temp.iloc[-1:].copy()\n",
        "        \n",
        "        # Atualiza lags com previsões anteriores\n",
        "        for lag in [1, 2, 3, 4, 52]:\n",
        "            lag_col = f'Weekly_Sales_lag_{lag}'\n",
        "            if lag_col in future_row.columns:\n",
        "                if i >= lag:\n",
        "                    # Usa previsão anterior\n",
        "                    future_row[lag_col] = predictions[i - lag]\n",
        "                else:\n",
        "                    # Usa valor histórico\n",
        "                    hist_idx = len(df_historical) - lag + i\n",
        "                    if hist_idx >= 0 and hist_idx < len(df_historical):\n",
        "                        future_row[lag_col] = df_historical['Weekly_Sales'].iloc[hist_idx]\n",
        "        \n",
        "        # Prepara features para predição (garante que todas as colunas necessárias estão presentes)\n",
        "        X_future = future_row[feature_cols].copy()\n",
        "        \n",
        "        # Previsão\n",
        "        pred = pipe.predict(X_future)[0]\n",
        "        predictions.append(pred)\n",
        "        \n",
        "        # Atualiza DataFrame de trabalho para próximos lags\n",
        "        future_row['Weekly_Sales'] = pred\n",
        "        df_working = pd.concat([df_working, future_row], ignore_index=True)\n",
        "    \n",
        "    # Cria DataFrame final com previsões\n",
        "    df_forecast = pd.DataFrame({\n",
        "        'Date': future_dates,\n",
        "        'Weekly_Sales_Predicted': predictions\n",
        "    })\n",
        "    \n",
        "    # Adiciona features externas para referência\n",
        "    for col in ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Holiday_Flag']:\n",
        "        if col in df_historical.columns:\n",
        "            df_forecast[col] = recent_mean.get(col, last_row.get(col, 0))\n",
        "    \n",
        "    return df_forecast\n",
        "\n",
        "\n",
        "# Gera previsões para as próximas 12 semanas\n",
        "n_weeks_forecast = 12\n",
        "df_forecast = forecast_future(df_model, pipe_best, feature_cols, n_weeks=n_weeks_forecast)\n",
        "\n",
        "print(f'Previsões geradas para as próximas {n_weeks_forecast} semanas:')\n",
        "display(df_forecast[['Date', 'Weekly_Sales_Predicted']].head(10))\n",
        "\n",
        "# Gráfico: histórico + previsão\n",
        "fig_forecast, ax_forecast = plt.subplots(figsize=(12, 5))\n",
        "\n",
        "# Histórico (últimas 26 semanas)\n",
        "hist_window = min(26, len(df_model))\n",
        "hist_dates = df_model[DATE_COL].iloc[-hist_window:]\n",
        "hist_sales = df_model[TARGET].iloc[-hist_window:]\n",
        "\n",
        "ax_forecast.plot(hist_dates, hist_sales.values, label='Histórico (últimas 26 semanas)', \n",
        "                color='#4C72B0', linewidth=2, alpha=0.7)\n",
        "ax_forecast.plot(df_forecast['Date'], df_forecast['Weekly_Sales_Predicted'], \n",
        "                label=f'Previsão ({n_weeks_forecast} semanas)', \n",
        "                color='#55A868', linewidth=2, linestyle='--', marker='o', markersize=4)\n",
        "\n",
        "# Conecta histórico com previsão\n",
        "if len(hist_dates) > 0:\n",
        "    last_hist_date = hist_dates.iloc[-1]\n",
        "    last_hist_value = hist_sales.iloc[-1]\n",
        "    first_forecast_date = df_forecast['Date'].iloc[0]\n",
        "    first_forecast_value = df_forecast['Weekly_Sales_Predicted'].iloc[0]\n",
        "    \n",
        "    ax_forecast.plot([last_hist_date, first_forecast_date], \n",
        "                   [last_hist_value, first_forecast_value], \n",
        "                   color='#55A868', linestyle='--', alpha=0.5)\n",
        "\n",
        "ax_forecast.axvline(x=hist_dates.iloc[-1] if len(hist_dates) > 0 else df_forecast['Date'].iloc[0], \n",
        "                   color='red', linestyle=':', alpha=0.5, label='Hoje')\n",
        "ax_forecast.set_xlabel('Data')\n",
        "ax_forecast.set_ylabel('Vendas Semanais')\n",
        "ax_forecast.set_title(f'Previsão de Vendas - Próximas {n_weeks_forecast} semanas')\n",
        "ax_forecast.legend()\n",
        "ax_forecast.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Métricas agregadas da previsão\n",
        "print('\\nMétricas da Previsão Futura:')\n",
        "print(f\"Média Prevista: R$ {df_forecast['Weekly_Sales_Predicted'].mean():,.0f}\")\n",
        "print(f\"Pico Previsto: R$ {df_forecast['Weekly_Sales_Predicted'].max():,.0f}\")\n",
        "print(f\"Mínimo Previsto: R$ {df_forecast['Weekly_Sales_Predicted'].min():,.0f}\")\n",
        "\n",
        "print('\\nNota: As previsões futuras usam médias recentes para variáveis externas.')\n",
        "print('Para cenários mais precisos, considere usar projeções macroeconômicas reais.')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
